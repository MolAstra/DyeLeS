{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "import numpy as np\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_dye_data(data_dir: Path) -> pd.DataFrame:\n",
    "    \"\"\"加载和合并荧光染料数据集\"\"\"\n",
    "    fluor_data_dir = data_dir / \"dyes\"\n",
    "    \n",
    "    # 检查目录是否存在\n",
    "    if not fluor_data_dir.exists() or not fluor_data_dir.is_dir():\n",
    "        logger.error(f\"目录 {fluor_data_dir} 不存在或不是有效的目录。\")\n",
    "        return pd.DataFrame()  # 返回空 DataFrame\n",
    "\n",
    "    # 文件名列表\n",
    "    files = [\n",
    "        \"Dataset_Consolidation_canonicalized.csv\",\n",
    "        \"Dataset_Cyanine_canonicalized.csv\",\n",
    "        \"Dataset_Xanthene_canonicalized.csv\",\n",
    "    ]\n",
    "\n",
    "    # 检查文件是否存在\n",
    "    missing_files = [f for f in files if not (fluor_data_dir / f).exists()]\n",
    "    if missing_files:\n",
    "        logger.error(f\"以下文件缺失: {', '.join(missing_files)}\")\n",
    "        return pd.DataFrame()  # 返回空 DataFrame\n",
    "\n",
    "    # 加载数据\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            df = pd.read_csv(fluor_data_dir / file)\n",
    "            dfs.append(df)\n",
    "            logger.info(f\"成功加载文件: {file}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"加载文件 {file} 时出错: {e}\")\n",
    "            return pd.DataFrame()  # 出错时返回空 DataFrame\n",
    "\n",
    "    # 合并数据并去重\n",
    "    merged_df = pd.concat(dfs, ignore_index=True).reset_index(drop=True)\n",
    "    n_stokes_shift = 0\n",
    "    n_emission_absorption = 0\n",
    "    for index, row in merged_df.iterrows():\n",
    "        if row[\"stokes_shift\"]:\n",
    "            n_stokes_shift += 1\n",
    "            continue\n",
    "        elif row[\"emission\"] and row[\"absorption\"]:\n",
    "            n_emission_absorption += 1\n",
    "            merged_df.loc[index, \"stokes_shift\"] = row[\"emission\"] - row[\"absorption\"]\n",
    "        else:\n",
    "            merged_df.loc[index, \"stokes_shift\"] = None\n",
    "            \n",
    "    logger.info(f\"Stokes shift 计算成功: {n_stokes_shift} 条数据，{n_emission_absorption} 条数据需要计算。\")\n",
    "    # 选择所需列\n",
    "    merged_df = merged_df[[\"smiles\", \"absorption\",\"emission\",\"stokes_shift\", \"quantum_yield\"]]\n",
    "    merged_df.dropna(inplace=True)\n",
    "    merged_df = merged_df.drop_duplicates(subset=[\"smiles\"], keep=\"first\")\n",
    "    \n",
    "    # 重置索引\n",
    "    merged_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # 输出加载的数据量\n",
    "    logger.info(f\"已加载 {len(merged_df)} 条唯一 SMILES 数据。\")\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 12:37:42.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_merge_dye_data\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1m成功加载文件: Dataset_Consolidation_canonicalized.csv\u001b[0m\n",
      "\u001b[32m2025-04-22 12:37:42.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_merge_dye_data\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1m成功加载文件: Dataset_Cyanine_canonicalized.csv\u001b[0m\n",
      "\u001b[32m2025-04-22 12:37:42.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_merge_dye_data\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1m成功加载文件: Dataset_Xanthene_canonicalized.csv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 12:37:43.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_merge_dye_data\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mStokes shift 计算成功: 39398 条数据，0 条数据需要计算。\u001b[0m\n",
      "\u001b[32m2025-04-22 12:37:43.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mload_and_merge_dye_data\u001b[0m:\u001b[36m58\u001b[0m - \u001b[1m已加载 6703 条唯一 SMILES 数据。\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../data\")\n",
    "df = load_and_merge_dye_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>absorption</th>\n",
       "      <th>emission</th>\n",
       "      <th>stokes_shift</th>\n",
       "      <th>quantum_yield</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6703.000000</td>\n",
       "      <td>6703.000000</td>\n",
       "      <td>6703.000000</td>\n",
       "      <td>6703.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>453.898255</td>\n",
       "      <td>530.709085</td>\n",
       "      <td>76.811428</td>\n",
       "      <td>0.350122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>117.823913</td>\n",
       "      <td>107.912885</td>\n",
       "      <td>50.847197</td>\n",
       "      <td>0.288046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>222.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>367.000000</td>\n",
       "      <td>447.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.084000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>423.000000</td>\n",
       "      <td>521.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>519.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>943.000000</td>\n",
       "      <td>1097.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        absorption     emission  stokes_shift  quantum_yield\n",
       "count  6703.000000  6703.000000   6703.000000    6703.000000\n",
       "mean    453.898255   530.709085     76.811428       0.350122\n",
       "std     117.823913   107.912885     50.847197       0.288046\n",
       "min     222.000000   247.000000      1.000000       0.000040\n",
       "25%     367.000000   447.000000     33.000000       0.084000\n",
       "50%     423.000000   521.000000     70.000000       0.290000\n",
       "75%     519.000000   598.000000    111.000000       0.600000\n",
       "max     943.000000  1097.000000    325.000000       1.000000"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def smiles_to_morgan_fingerprint(smiles: str, radius: int = 2, n_bits: int = 2048):\n",
    "    \"\"\"将 SMILES 字符串转化为摩根指纹\"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return np.zeros(n_bits)  # 无效 SMILES，返回零向量\n",
    "    fingerprint = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=n_bits)\n",
    "    return np.array(fingerprint)\n",
    "\n",
    "def train_lightgbm_model(df: pd.DataFrame):\n",
    "    \"\"\"使用 LightGBM 和 MultiOutputRegressor 训练模型同时预测 absorption、emission、stokes_shift 和 quantum_yield\"\"\"\n",
    "    \n",
    "    # 1. 数据预处理\n",
    "    logger.info(\"Converting SMILES to Morgan Fingerprints...\")\n",
    "    fingerprints = df[\"smiles\"].apply(smiles_to_morgan_fingerprint)\n",
    "    X = pd.DataFrame(fingerprints.tolist())  # 转成 DataFrame，保持特征名一致\n",
    "\n",
    "    y = df[[\"absorption\", \"emission\", \"stokes_shift\", \"quantum_yield\"]]\n",
    "\n",
    "    # 2. 划分数据集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    # 3. 模型定义与训练\n",
    "    logger.info(\"Training model for absorption, emission, stokes_shift, and quantum_yield...\")\n",
    "    lgb_model = lgb.LGBMRegressor(objective=\"regression\")\n",
    "    multioutput_model = MultiOutputRegressor(lgb_model)\n",
    "\n",
    "    multioutput_model.fit(X_train, y_train)\n",
    "\n",
    "    # 4. 预测与评估\n",
    "    logger.info(\"Making predictions on the test set...\")\n",
    "    y_pred = multioutput_model.predict(X_test)\n",
    "\n",
    "    metrics = {}\n",
    "    targets = [\"absorption\", \"emission\", \"stokes_shift\", \"quantum_yield\"]\n",
    "    for idx, target in enumerate(targets):\n",
    "        mse = mean_squared_error(y_test[target], y_pred[:, idx])\n",
    "        r2 = r2_score(y_test[target], y_pred[:, idx])\n",
    "        metrics[target] = {\"MSE\": mse, \"R2\": r2}\n",
    "        logger.info(f\"{target} - MSE: {mse:.4f}, R2: {r2:.4f}\")\n",
    "\n",
    "    return multioutput_model, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 12:40:45.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_lightgbm_model\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mConverting SMILES to Morgan Fingerprints...\u001b[0m\n",
      "\u001b[32m2025-04-22 12:40:58.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_lightgbm_model\u001b[0m:\u001b[36m25\u001b[0m - \u001b[1mTraining model for absorption, emission, stokes_shift, and quantum_yield...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3242\n",
      "[LightGBM] [Info] Number of data points in the train set: 6032, number of used features: 1621\n",
      "[LightGBM] [Info] Start training from score 455.088031\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3242\n",
      "[LightGBM] [Info] Number of data points in the train set: 6032, number of used features: 1621\n",
      "[LightGBM] [Info] Start training from score 531.524038\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3242\n",
      "[LightGBM] [Info] Number of data points in the train set: 6032, number of used features: 1621\n",
      "[LightGBM] [Info] Start training from score 76.436505\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030833 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3242\n",
      "[LightGBM] [Info] Number of data points in the train set: 6032, number of used features: 1621\n",
      "[LightGBM] [Info] Start training from score 0.349749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-22 12:41:00.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_lightgbm_model\u001b[0m:\u001b[36m32\u001b[0m - \u001b[1mMaking predictions on the test set...\u001b[0m\n",
      "\u001b[32m2025-04-22 12:41:00.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_lightgbm_model\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mabsorption - MSE: 1456.0986, R2: 0.8839\u001b[0m\n",
      "\u001b[32m2025-04-22 12:41:00.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_lightgbm_model\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1memission - MSE: 1847.3987, R2: 0.8274\u001b[0m\n",
      "\u001b[32m2025-04-22 12:41:00.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_lightgbm_model\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mstokes_shift - MSE: 881.0986, R2: 0.6629\u001b[0m\n",
      "\u001b[32m2025-04-22 12:41:00.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mtrain_lightgbm_model\u001b[0m:\u001b[36m41\u001b[0m - \u001b[1mquantum_yield - MSE: 0.0444, R2: 0.4833\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model, _ = train_lightgbm_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../dyeles/resources/lightgbm.pkl\", \"wb\") as f:\n",
    "    joblib.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DyeLeS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
